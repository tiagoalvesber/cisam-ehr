{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a07ecd-d5e5-4925-8f2d-57b19467c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "import traceback\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import entity_to_acronyms, acronyms_to_entities, colors, index_to_label\n",
    "\n",
    "json_labels = entity_to_acronyms\n",
    "\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572a777-1e1a-401b-839f-d11f239ed671",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/home/tiagolima/Datasets/CISAM/dataset/data'\n",
    "dataset_dir = '/home/tiagolima/Datasets/CISAM/adapted/'\n",
    "output_dir = \"../data/bio_stanford\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir,  exist_ok=True, mode=0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb5bbad2-7d0e-4fcc-9326-368619de814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de substituição que troca ',' por '.' somente dentro de números\n",
    "def substituir_virgula_por_ponto(match):\n",
    "    return match.group(0).replace(',', '.')\n",
    "\n",
    "def substituir_virgula_por_espaco(match):\n",
    "    return ' ' + match.group(1)\n",
    "\n",
    "def substituir_doispontos_entre_value_labels(match):\n",
    "    return match.group(1) + \" \" + match.group(2)\n",
    "\n",
    "\n",
    "pattern_dots_inside = r'(\\b[a-zA-Z]+)\\:(\\d+\\b)'\n",
    "\n",
    "pattern_slash_space = re.compile(r'(?<=[a-zA-Z])/(?=[a-zA-Z])')\n",
    "pattern_norm_number = re.compile(r'\\d+,\\d+')\n",
    "pattern_replace_virgula = re.compile(r',\\s*(\\w)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b70c042f-301b-4c4e-a657-acd6ee8d5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituir_virgulas_nao_datas(texto):\n",
    "    # Expressão regular para encontrar datas nos formatos DD/MM/AAAA ou DD/MM\n",
    "    data_pattern = re.compile(r'\\b\\d{2}/\\d{2}(?:/\\d{4})?\\b')\n",
    "    # Lista para armazenar posições de datas\n",
    "    posicoes_datas = [(m.start(), m.end()) for m in data_pattern.finditer(texto)]\n",
    "\n",
    "    # Função auxiliar para verificar se uma posição está dentro de uma data\n",
    "    def esta_em_data(pos):\n",
    "        for start, end in posicoes_datas:\n",
    "            if start <= pos < end:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Construir o resultado substituindo \"/\" por espaço onde aplicável\n",
    "    resultado = []\n",
    "    i = 0\n",
    "    while i < len(texto):\n",
    "        if texto[i] == '/' and not esta_em_data(i):\n",
    "            resultado.append(' ')\n",
    "        else:\n",
    "            resultado.append(texto[i])\n",
    "        i += 1\n",
    "\n",
    "    return ''.join(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff49e7-b649-4d65-8014-f88f8013523a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d489d679-d9c4-4374-84b1-72193b466b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverter chaves e valores\n",
    "json_labels_inverted = {valor: chave for chave, valor in json_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d47e6d-24dd-4f76-8977-d714f4807e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_colon(text):\n",
    "    # Define a regex pattern to match time strings (e.g., 12:34, 23:59, etc.)\n",
    "    time_pattern = r'\\b\\d{1,2}:\\d{2}\\b'\n",
    "\n",
    "    # Find all time patterns in the text\n",
    "    time_matches = re.findall(time_pattern, text)\n",
    "\n",
    "    # Replace all colons except those in time patterns\n",
    "    def replacer(match):\n",
    "        # If the match is a time pattern, return it unchanged\n",
    "        if match.group() in time_matches:\n",
    "            return match.group()\n",
    "        # Otherwise, replace the colon with a space\n",
    "        return match.group().replace(':', ' ')\n",
    "\n",
    "    # Use re.sub with a callback function to selectively replace colons\n",
    "    result = re.sub(r'\\S+:\\S+', replacer, text)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3e69625-3255-4a04-9eef-6060ba9ce152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_terminal_periods(text):\n",
    "    # Define a regex pattern to match periods at the end of a line\n",
    "    terminal_period_pattern = r'(?<!\\d)\\.(?=\\s*$)'\n",
    "\n",
    "    # Use re.sub to replace terminal periods with an empty string\n",
    "    result = re.sub(terminal_period_pattern, '', text, flags=re.MULTILINE)\n",
    "\n",
    "    return result\n",
    "\n",
    "def remove_non_decimal_periods(text):\n",
    "    # Define a regex pattern to match periods that are not part of a number (decimal point)\n",
    "    non_decimal_period_pattern = r'(?<!\\d)\\.(?!\\d)'\n",
    "\n",
    "    # Use re.sub to replace non-decimal periods that are not at the end of a line\n",
    "    result = re.sub(non_decimal_period_pattern, '', text)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a89a78f9-bcb8-4a0c-be4e-f5434902861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_concatenated_commas(text):\n",
    "    # Remove commas that are concatenated with words (without spaces in between)\n",
    "    text = re.sub(r'(?<=[^\\s,]),(?=[^\\s,])', ' ', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "367fe4c9-e51f-4e71-a272-8b887379bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_commas_with_spaces(text):\n",
    "    # Replace all commas with spaces\n",
    "    return text.replace(',', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d069de74-a628-479f-9a4e-d6af80233bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_commas_with_equals(text):\n",
    "    # Replace all commas with spaces\n",
    "    return text.replace('=', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797654a2-d2f7-444a-aee8-088d9f98750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_json(data_dir):\n",
    "    doc_ids = []\n",
    "    # print(\"AQUIIIIIIIIIIIIIIII  data_dir\", data_dir)\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            # print(\"AQUIIIIIIIIIIIIIIII  filename\", filename)\n",
    "            if filename.endswith('jsonl'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = f.readlines()\n",
    "                for jsonl in data:\n",
    "                    jsonl = json.loads(jsonl)\n",
    "\n",
    "                    \n",
    "                    sessions = {}\n",
    "                    counter_terms = 1\n",
    "                    counter_clinical_events = 1\n",
    "                    counter_relation = 1\n",
    "                    counter_session = 1\n",
    "\n",
    "                    pool_events = []\n",
    "                    text = jsonl['text'].lower()\n",
    "    \n",
    "                    with open(os.path.join(output_dir, f'{jsonl[\"id\"]:06d}.txt'), 'w') as file_events:\n",
    "                        file_events.write(text)\n",
    "                    ann_events = open(os.path.join(output_dir, f'{jsonl[\"id\"]:06d}.ann'), 'w')\n",
    "\n",
    "                    \n",
    "                    for entity in jsonl['entities']:\n",
    "                        pool_events.append({'start': entity['start_offset'], 'end': entity['end_offset'], 'label': entity['label']})\n",
    "\n",
    "                    for entity in jsonl['sessions']:\n",
    "                        # print(entity.keys())\n",
    "                        if 'startOffset' in entity.keys():\n",
    "                            start = 'startOffset'\n",
    "                            end = 'endOffset'\n",
    "                            pool_events.append({'start': entity[start], 'end': entity[end], 'session': entity['session']})\n",
    "                        else:\n",
    "                            start = 'start'\n",
    "                            end = 'end'\n",
    "                            pool_events.append({'start': entity[start], 'end': entity[end], 'session': entity['label']})\n",
    "                        \n",
    "\n",
    "                    pool_events_ordered = sorted(pool_events, key=lambda dicionario: dicionario['start'])\n",
    "                    \n",
    "                    # print(\"*\" * 50, '\\n', pool_events_ordered)\n",
    "                    \n",
    "                    for pp in pool_events_ordered:\n",
    "\n",
    "                        if 'session' in pp.keys():\n",
    "                            ann_events.write(f\"S{counter_session}\\t{'Session'} {pp['start']} {pp['end']}\\t{pp['session']}\\n\")\n",
    "                            counter_session += 1\n",
    "                        else:\n",
    "                            # print(f\"T{counter_terms} {json_labels_inverted[pp['label']]} {pp['start']} {pp['end']}\\t{text[pp['start']:pp['end']]}\")\n",
    "                            ann_events.write(f\"T{counter_terms}\\t{json_labels_inverted[pp['label']]} {pp['start']} {pp['end']}\\t{text[pp['start']:pp['end']]} \\n\")\n",
    "                            if json_labels_inverted[pp['label']] in ['Clinical_event', 'Sign_symptom', 'Date', 'Medication', 'Time']:\n",
    "                                # print(f\"E{counter_clinical_events} {json_labels_inverted[pp['label']]}:T{counter_terms}\")\n",
    "                                ann_events.write(f\"E{counter_clinical_events}\\t{json_labels_inverted[pp['label']]}:T{counter_terms} \\n\")\n",
    "                                counter_clinical_events += 1\n",
    "                            counter_terms+=1\n",
    "                    ann_events.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "657bc36c-1ddb-4bf2-a04e-604dd0cbe7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_docs_json(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4754316-1f79-4451-8c2b-e8e51aa3d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_docs_json(data_dir):\n",
    "    data_reference = \"/home/tiagolima/Datasets/CISAM/dataset/5K_data/0001/\"\n",
    "\n",
    "    _meddle = \"/home/tiagolima/Datasets/CISAM/dataset/5K_data/0001_meddle/\"\n",
    "    if not os.path.exists(_meddle):\n",
    "        os.makedirs(_meddle,  exist_ok=True, mode=0o777)\n",
    "    \n",
    "    reference_dic = {}\n",
    "    for root, _, files in os.walk(data_reference):\n",
    "        for filename in files:\n",
    "            if filename.endswith('json'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.loads(f.read())\n",
    "                    reference_dic[data['id']] = file_path\n",
    "    do_remover = []\n",
    "    \n",
    "    doc_ids = []\n",
    "\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith('jsonl'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = f.readlines()\n",
    "                    \n",
    "                for jsonl in data:\n",
    "                    jsonl = json.loads(jsonl)\n",
    "                    if jsonl['id'] in reference_dic.keys():\n",
    "                        do_remover.append(jsonl['id'])\n",
    "    for d in do_remover:\n",
    "        del reference_dic[d]\n",
    "    print(len(reference_dic))\n",
    "    \n",
    "    for source in reference_dic.values():\n",
    "        destination = os.path.join(_meddle,os.path.basename(source))\n",
    "        dest = shutil.copy(source, destination) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3e4caec-3cc0-47af-9d68-a83cfea8b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_docs_json(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80a2f5-8863-4ef7-a312-86390d5ffb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cecfd-0dd2-4b10-bdd0-39bfc97f77d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
